


# I have a docs
# I have imagery




import os, sys
from pathlib import Path
from typing import List

import pandas as pd
import geopandas as gpd


dir_path = Path(os.getcwd()).parent.parent

# Universe
UNIVERSE_PATH = dir_path / 'src/streetTransformer/data/universes/caprecon3'

# Documents
DOCUMENTS_PATH = dir_path.parent / 'proj_data/project_documents/'
documents_df = pd.read_csv(DOCUMENTS_PATH / 'projects_df.csv', index_col=0)

# Imagery
IMAGERY_PATH = UNIVERSE_PATH / 'imagery/'

# Locations
LOCATIONS_PATH = UNIVERSE_PATH / 'locations.feather'



locations_gdf = gpd.read_feather(LOCATIONS_PATH)
#os.listdir(IMAGERY_PATH)

os.listdir(IMAGERY_PATH / '2006')



# import json
# documents_geocode = pd.read_json(dir_path / 'gemini_output.ndjson', lines=True)#.set_index('id')

# cleaned_text = documents_geocode.set_index('id')['text'].str.replace('  ', '').str.replace('\n', '')
# temp_df = pd.DataFrame(cleaned_text.apply(load_json)[13])

# temp_df[['lat','lng']] = pd.DataFrame(temp_df['coordinates'].tolist(), index=temp_df.index)
# gpd.GeoDataFrame(temp_df, geometry=gpd.points_from_xy(temp_df['lat'], temp_df['lng'], crs='4326'))



import json
import numpy as np
import pandas as pd
import geopandas as gpd

def _load_json_safe(x):
    try: 
        return json.loads(x)
    except Exception as e:
        #print(x, e)
        return ''

s = (
    documents_geocode['text']
    .str.replace(r'\s+', ' ', regex=True)
    .str.strip()
)
parsed_json = s.apply(_load_json_safe)

# Flatten list-like JSONs into one long Series of dicts
flat = (
    parsed_json.dropna()
          .map(lambda v: v if isinstance(v, (list, tuple)) else [v])
          .explode()
)

location_id = flat.index
temp_df = pd.json_normalize(flat)

coordinates_df = pd.DataFrame(
    temp_df.dropna(subset='coordinates')['coordinates'].tolist(),
    index=temp_df.dropna(subset='coordinates').index, 
    columns=['lat','lng']
)

merged_df = temp_df.merge(
    coordinates_df,
    left_index=True, right_index=True,
    how='left'
)

merged_gdf = gpd.GeoDataFrame(merged_df, geometry=gpd.points_from_xy(merged_df['lat'], merged_df['lng']), crs='4326')

saved_lats = merged_gdf['lat']
swap_latlngs = merged_gdf[saved_lats < 0][['lat','lng']]
# swap_lngs = saved_lngs[saved_lngs < 0]

#merged_gdf.dropna(subset=['lat','lng'])[['lat','lng']]
merged_gdf.loc[swap_latlngs.index, ['lng','lat']] = swap_latlngs.values

#merged_gdf['lng'].hist()
#merged_gdf['lat'].hist()
#merged_gdf[merged_gdf['lat'] < 0]
merged_gdf['geometry'] = gpd.points_from_xy(merged_gdf['lat'], merged_gdf['lng'])
merged_gdf.plot()


# This is the real pipeline
def _load_json_safe(x):
    try: 
        return json.loads(x)
    except Exception as e:
        #print(x, e)
        return ''

s = (
    documents_geocode['text']
    .str.replace(r'\s+', ' ', regex=True)
    .str.strip()
)
parsed_json = s.apply(_load_json_safe)


t = pd.DataFrame(parsed_json)
t['id'] = documents_geocode['id']
t = t.set_index('id')

flat = (
    t.dropna()
          .map(lambda v: v if isinstance(v, (list, tuple)) else [v])['text']
          .explode()
)

location_id = flat.index
temp_df = pd.json_normalize(flat)

coordinates_df = pd.DataFrame(
    temp_df.dropna(subset='coordinates')['coordinates'].tolist(),
    index=temp_df.dropna(subset='coordinates').index, 
    columns=['lat','lng']
)

merged_df = temp_df.merge(
    coordinates_df,
    left_index=True, right_index=True,
    how='left'
)

merged_df['location_id'] = location_id
merged_df

merged_gdf = gpd.GeoDataFrame(merged_df, geometry=gpd.points_from_xy(merged_df['lat'], merged_df['lng']), crs='4326')

saved_lats = merged_gdf['lat']
swap_latlngs = merged_gdf[saved_lats < 0][['lat','lng']]

merged_gdf.loc[swap_latlngs.index, ['lng','lat']] = swap_latlngs.values

merged_gdf['geometry'] = gpd.points_from_xy(merged_gdf['lat'], merged_gdf['lng'])
merged_gdf.plot()



#!pip install folium
# import folium
# from IPython.display import display, HTML

# def folium_deepnote_show(m):
#     data = m.get_root().render()
#     data_fixed_height = data.replace('width: 100%;height: 100%', 'width: 100%').replace('height: 100.0%;', 'height: 609px;', 1)
#     display(HTML(data_fixed_height))

# map_center = [float(merged_gdf['lng'].mean()), float(merged_gdf['lat'].mean())]
# map_center
# m = folium.Map(location=map_center, zoom_start=13)

# # # Display the map using the custom function
# # documents_df.merge(
# #     merged_gdf,
# #     left_index=True, right_on = 'location_id',
# #     how='left'
# # )

# # merged_gdf.merge(
# #     documents_df,
# #     left_on = 'location_id', right_index=True,
# #     how='right'
# # ).explore(m=m)

# folium_deepnote_show(m)

# import folium
# m = folium.Map(location=[0, 0], zoom_start=2)
# folium_deepnote_show(m)


merged_gdf



merged_gdf.dropna(subset=['lat','lng'])





merged_gdf.dropna(subset=['lat', 'lng']).plot()


#documents_df.merge(merged_gdf, left_index=True, right_index=True).dropna(subset=['lat','lng'])


documents_df


from align_docs_and_projects import pipeline
import os
from pathlib import Path
DIR_PATH = Path(os.curdir).resolve().parent.parent
json_path = DIR_PATH / 'data/project_documents/geocoded' / 'gemini_output2.ndjson'
json_path = DIR_PATH / 'data/project_documents/geocoded' / 'gemini_output.ndjson'
geocoded_documents = pipeline(json_path)
#geocoded_documents[geocoded_documents['lat'] < 40]


# Now load locations
import geopandas as gpd
UNIVERSE_PATH = DIR_PATH / 'src/streetTransformer/data/universes/caprecon3'

LOCATIONS_PATH =  UNIVERSE_PATH / 'locations.feather'
locations_gdf_p = gpd.read_feather(LOCATIONS_PATH)

locations_gdf = locations_gdf_p.to_crs('4326')

BUFFER_WIDTH = 50

locations_buffered = locations_gdf_p.buffer(BUFFER_WIDTH)
locations_gdf_p['buffer'] = locations_buffered
locations_gdf_p = locations_gdf_p.rename({'NODEID':'location_id'}, axis=1)

joined_docs_locations_gdf = locations_gdf_p.set_geometry('buffer').sjoin(
    geocoded_documents.to_crs(locations_gdf_p.crs)
).rename({'index_right': 'doc_location_id'}, axis=1)

joined_docs_locations_gdf = joined_docs_locations_gdf.rename({'coordinates': 'document_coords'}, axis=1)
joined_docs_locations_gdf[[
    'location_id', 'document_id', 'doc_location_id', # IDs
    'cross_streets', 'StreetNames',
    'geometry','buffer','document_coords' # geometries
]]


# geocoded_documents.to_crs(locations_gdf_p.crs).plot()
# locations_gdf_p.to_crs(locations_gdf_p.crs).plot()
# geocoded_documents.to_crs(locations_gdf_p.crs)

geocoded_documents#.explore()

geocoded_documents['geometry'] = (gpd.points_from_xy(geocoded_documents['lng'], geocoded_documents['lat']))

geocoded_documents[
    (geocoded_documents['lat'].notna()) & 
    (geocoded_documents['lng'] < 0) & 
    (geocoded_documents['lat'] > 38) & 
    (geocoded_documents.geometry.is_valid)
].explore()#tiles='CartoDB DarkMatter')


!
